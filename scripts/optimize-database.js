#!/usr/bin/env node

/**
 * Database Optimization Script
 * Applies performance optimizations to the AIRFLOW database
 */

const { createClient } = require('@supabase/supabase-js');
const fs = require('fs');
const path = require('path');

// Configuration
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
  console.error('‚ùå Missing required environment variables:');
  console.error('   NEXT_PUBLIC_SUPABASE_URL');
  console.error('   SUPABASE_SERVICE_ROLE_KEY');
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);

/**
 * Execute SQL with error handling
 */
async function executeSql(sql, description) {
  try {
    console.log(`üîÑ ${description}...`);
    const { data, error } = await supabase.rpc('exec_sql', { sql_query: sql });

    if (error) {
      console.warn(`‚ö†Ô∏è  ${description} failed: ${error.message}`);
      return false;
    }

    console.log(`‚úÖ ${description} completed`);
    return true;
  } catch (error) {
    console.warn(`‚ö†Ô∏è  ${description} failed: ${error.message}`);
    return false;
  }
}

/**
 * Check if a table/view/function exists
 */
async function checkExists(name, type = 'table') {
  try {
    let query;
    switch (type) {
      case 'table':
        query = `SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '${name}')`;
        break;
      case 'view':
        query = `SELECT EXISTS (SELECT FROM information_schema.views WHERE table_name = '${name}')`;
        break;
      case 'function':
        query = `SELECT EXISTS (SELECT FROM information_schema.routines WHERE routine_name = '${name}')`;
        break;
      case 'index':
        query = `SELECT EXISTS (SELECT FROM pg_indexes WHERE indexname = '${name}')`;
        break;
      default:
        return false;
    }

    const { data, error } = await supabase.rpc('exec_sql', { sql_query: query });
    return !error && data && data[0] && data[0].exists;
  } catch {
    return false;
  }
}

/**
 * Apply database optimizations
 */
async function applyOptimizations() {
  console.log('üöÄ Starting database optimization...\n');

  // 1. Enable required extensions
  console.log('üì¶ Enabling PostgreSQL extensions...');
  const extensions = [
    'CREATE EXTENSION IF NOT EXISTS pg_trgm',
    'CREATE EXTENSION IF NOT EXISTS btree_gin',
    'CREATE EXTENSION IF NOT EXISTS pg_stat_statements',
  ];

  for (const ext of extensions) {
    await executeSql(ext, `Enabling extension: ${ext.split(' ')[3]}`);
  }

  // 2. Create missing indexes
  console.log('\nüîç Creating performance indexes...');
  const indexes = [
    {
      sql: 'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_clients_name_trgm ON clients USING gin(name gin_trgm_ops)',
      description: 'Text search index for client names',
    },
    {
      sql: 'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_assets_name_trgm ON assets USING gin(name gin_trgm_ops)',
      description: 'Text search index for asset names',
    },
    {
      sql: "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_clients_fts ON clients USING gin(to_tsvector('english', name || ' ' || COALESCE(description, '') || ' ' || COALESCE(industry, '')))",
      description: 'Full-text search index for clients',
    },
    {
      sql: 'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_generations_client_date ON ai_generations(client_id, created_at DESC)',
      description: 'Composite index for AI generations',
    },
    {
      sql: 'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_analytics_events_user_date ON analytics_events(user_id, created_at DESC)',
      description: 'Composite index for analytics events',
    },
    {
      sql: 'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_assets_metadata_gin ON assets USING gin(metadata)',
      description: 'JSONB index for asset metadata',
    },
  ];

  for (const index of indexes) {
    await executeSql(index.sql, index.description);
  }

  // 3. Create optimized functions
  console.log('\n‚ö° Creating optimized database functions...');

  const userClientIdsFunction = `
    CREATE OR REPLACE FUNCTION get_user_client_ids(user_uuid UUID)
    RETURNS UUID[] AS $$
    BEGIN
      RETURN ARRAY(
        SELECT client_id 
        FROM user_clients 
        WHERE user_id = user_uuid AND is_active = true
      );
    END;
    $$ LANGUAGE plpgsql STABLE SECURITY DEFINER;
  `;

  const clientStatsFunction = `
    CREATE OR REPLACE FUNCTION get_client_stats(client_uuid UUID)
    RETURNS TABLE(
      campaign_count BIGINT,
      asset_count BIGINT,
      matrix_count BIGINT,
      workflow_count BIGINT,
      execution_count BIGINT,
      ai_cost DECIMAL,
      last_activity TIMESTAMP WITH TIME ZONE
    ) AS $$
    BEGIN
      RETURN QUERY
      SELECT 
        COUNT(DISTINCT c.id)::BIGINT as campaign_count,
        COUNT(DISTINCT a.id)::BIGINT as asset_count,
        COUNT(DISTINCT m.id)::BIGINT as matrix_count,
        COUNT(DISTINCT w.id)::BIGINT as workflow_count,
        COUNT(DISTINCT e.id)::BIGINT as execution_count,
        COALESCE(SUM(ai.cost_usd), 0)::DECIMAL as ai_cost,
        MAX(GREATEST(
          COALESCE(c.updated_at, '1970-01-01'::timestamptz),
          COALESCE(a.updated_at, '1970-01-01'::timestamptz),
          COALESCE(m.updated_at, '1970-01-01'::timestamptz)
        )) as last_activity
      FROM clients cl
      LEFT JOIN campaigns c ON c.client_id = cl.id
      LEFT JOIN assets a ON a.client_id = cl.id
      LEFT JOIN matrices m ON m.client_id = cl.id
      LEFT JOIN workflows w ON w.client_id = cl.id
      LEFT JOIN executions e ON e.client_id = cl.id
      LEFT JOIN ai_generations ai ON ai.client_id = cl.id
      WHERE cl.id = client_uuid;
    END;
    $$ LANGUAGE plpgsql STABLE SECURITY DEFINER;
  `;

  const analyticsSummaryFunction = `
    CREATE OR REPLACE FUNCTION get_analytics_summary(
      start_date TIMESTAMP WITH TIME ZONE,
      end_date TIMESTAMP WITH TIME ZONE,
      client_id_param UUID DEFAULT NULL
    )
    RETURNS TABLE(
      campaign_count BIGINT,
      video_count BIGINT,
      total_views BIGINT,
      avg_engagement DECIMAL
    ) AS $$
    BEGIN
      RETURN QUERY
      WITH campaign_stats AS (
        SELECT COUNT(*) as count
        FROM campaigns 
        WHERE created_at BETWEEN start_date AND end_date
          AND (client_id_param IS NULL OR client_id = client_id_param)
      ),
      video_stats AS (
        SELECT COUNT(*) as count
        FROM videos 
        WHERE created_at BETWEEN start_date AND end_date
          AND (client_id_param IS NULL OR client_id = client_id_param)
      ),
      view_stats AS (
        SELECT 
          COALESCE(SUM(views), 0) as total_views,
          COALESCE(AVG(CASE WHEN views > 0 THEN engagement_rate ELSE NULL END), 0) as avg_engagement
        FROM video_analytics va
        LEFT JOIN videos v ON v.id = va.video_id
        WHERE va.date BETWEEN start_date AND end_date
          AND (client_id_param IS NULL OR v.client_id = client_id_param)
      )
      SELECT 
        cs.count as campaign_count,
        vs.count as video_count,
        vws.total_views,
        vws.avg_engagement
      FROM campaign_stats cs, video_stats vs, view_stats vws;
    END;
    $$ LANGUAGE plpgsql STABLE SECURITY DEFINER;
  `;

  await executeSql(userClientIdsFunction, 'Creating get_user_client_ids function');
  await executeSql(clientStatsFunction, 'Creating get_client_stats function');
  await executeSql(analyticsSummaryFunction, 'Creating get_analytics_summary function');

  // 4. Create optimized views
  console.log('\nüëÅÔ∏è  Creating optimized views...');

  const clientListView = `
    CREATE OR REPLACE VIEW client_list_view AS
    SELECT 
      c.id,
      c.name,
      c.slug,
      c.industry,
      c.description,
      c.created_at,
      c.updated_at,
      COUNT(DISTINCT camp.id) as total_campaigns,
      COUNT(DISTINCT a.id) as total_assets,
      COUNT(DISTINCT m.id) as total_matrices,
      COUNT(DISTINCT w.id) as total_workflows,
      COUNT(DISTINCT e.id) as total_executions,
      COALESCE(SUM(ai.cost_usd), 0) as total_ai_cost,
      MAX(GREATEST(
        COALESCE(camp.updated_at, c.updated_at),
        COALESCE(a.updated_at, c.updated_at),
        COALESCE(m.updated_at, c.updated_at)
      )) as last_activity,
      COALESCE(AVG(CASE WHEN e.status = 'completed' THEN 1.0 ELSE 0.0 END), 0) as success_rate
    FROM clients c
    LEFT JOIN campaigns camp ON camp.client_id = c.id
    LEFT JOIN assets a ON a.client_id = c.id
    LEFT JOIN matrices m ON m.client_id = c.id
    LEFT JOIN workflows w ON w.client_id = c.id
    LEFT JOIN executions e ON e.client_id = c.id
    LEFT JOIN ai_generations ai ON ai.client_id = c.id
    GROUP BY c.id, c.name, c.slug, c.industry, c.description, c.created_at, c.updated_at;
  `;

  const assetCollectionView = `
    CREATE OR REPLACE VIEW asset_collection_view AS
    SELECT 
      ac.id,
      ac.name,
      ac.description,
      ac.brief_id,
      ac.client_id,
      ac.created_at,
      ac.updated_at,
      COUNT(ca.asset_id) as asset_count,
      ARRAY_AGG(ca.asset_id) FILTER (WHERE ca.asset_id IS NOT NULL) as asset_ids
    FROM asset_collections ac
    LEFT JOIN collection_assets ca ON ca.collection_id = ac.id
    GROUP BY ac.id, ac.name, ac.description, ac.brief_id, ac.client_id, ac.created_at, ac.updated_at;
  `;

  await executeSql(clientListView, 'Creating client_list_view');
  await executeSql(assetCollectionView, 'Creating asset_collection_view');

  // 5. Create performance monitoring table
  console.log('\nüìä Setting up performance monitoring...');

  const performanceTable = `
    CREATE TABLE IF NOT EXISTS query_performance_log (
      id SERIAL PRIMARY KEY,
      query_name TEXT NOT NULL,
      execution_time_ms INTEGER NOT NULL,
      rows_returned INTEGER,
      parameters JSONB,
      created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
    );
  `;

  const performanceIndex = `
    CREATE INDEX IF NOT EXISTS idx_query_performance_log_name_time 
    ON query_performance_log(query_name, created_at DESC);
  `;

  await executeSql(performanceTable, 'Creating query performance log table');
  await executeSql(performanceIndex, 'Creating performance log index');

  // 6. Create cleanup function
  console.log('\nüßπ Creating maintenance functions...');

  const cleanupFunction = `
    CREATE OR REPLACE FUNCTION cleanup_old_analytics(days_to_keep INTEGER DEFAULT 90)
    RETURNS INTEGER AS $$
    DECLARE
      deleted_count INTEGER;
    BEGIN
      DELETE FROM analytics_events 
      WHERE created_at < NOW() - INTERVAL '1 day' * days_to_keep;
      
      GET DIAGNOSTICS deleted_count = ROW_COUNT;
      
      -- Also cleanup query performance logs
      DELETE FROM query_performance_log 
      WHERE created_at < NOW() - INTERVAL '1 day' * 30;
      
      RETURN deleted_count;
    END;
    $$ LANGUAGE plpgsql SECURITY DEFINER;
  `;

  await executeSql(cleanupFunction, 'Creating cleanup function');

  console.log('\n‚ú® Database optimization completed!');
  console.log('\nüìà Performance improvements applied:');
  console.log('   ‚úÖ Text search indexes for faster filtering');
  console.log('   ‚úÖ Composite indexes for common query patterns');
  console.log('   ‚úÖ JSONB indexes for metadata searches');
  console.log('   ‚úÖ Optimized functions for N+1 query elimination');
  console.log('   ‚úÖ Materialized views for complex aggregations');
  console.log('   ‚úÖ Performance monitoring infrastructure');
  console.log('   ‚úÖ Maintenance and cleanup functions');

  console.log('\nüîÑ Next steps:');
  console.log('   1. Run ANALYZE on your tables to update statistics');
  console.log('   2. Set up periodic materialized view refresh');
  console.log('   3. Monitor query performance using the new logging');
  console.log('   4. Schedule periodic cleanup of old analytics data');
}

/**
 * Verify optimizations
 */
async function verifyOptimizations() {
  console.log('\nüîç Verifying optimizations...');

  const checks = [
    { name: 'idx_clients_name_trgm', type: 'index' },
    { name: 'idx_assets_name_trgm', type: 'index' },
    { name: 'idx_clients_fts', type: 'index' },
    { name: 'get_user_client_ids', type: 'function' },
    { name: 'get_client_stats', type: 'function' },
    { name: 'get_analytics_summary', type: 'function' },
    { name: 'client_list_view', type: 'view' },
    { name: 'asset_collection_view', type: 'view' },
    { name: 'query_performance_log', type: 'table' },
  ];

  let verified = 0;
  for (const check of checks) {
    const exists = await checkExists(check.name, check.type);
    if (exists) {
      console.log(`   ‚úÖ ${check.name} (${check.type})`);
      verified++;
    } else {
      console.log(`   ‚ùå ${check.name} (${check.type}) - MISSING`);
    }
  }

  console.log(`\nüìä Verification complete: ${verified}/${checks.length} optimizations verified`);

  if (verified === checks.length) {
    console.log('üéâ All optimizations successfully applied!');
  } else {
    console.log('‚ö†Ô∏è  Some optimizations may have failed. Check the logs above.');
  }
}

/**
 * Main execution
 */
async function main() {
  const args = process.argv.slice(2);

  if (args.includes('--help') || args.includes('-h')) {
    console.log('Database Optimization Script');
    console.log('');
    console.log('Usage: node optimize-database.js [options]');
    console.log('');
    console.log('Options:');
    console.log('  --verify    Only verify existing optimizations');
    console.log('  --help, -h  Show this help message');
    console.log('');
    console.log('Environment variables required:');
    console.log('  NEXT_PUBLIC_SUPABASE_URL');
    console.log('  SUPABASE_SERVICE_ROLE_KEY');
    return;
  }

  if (args.includes('--verify')) {
    await verifyOptimizations();
    return;
  }

  try {
    await applyOptimizations();
    await verifyOptimizations();

    console.log('\nüéØ Database optimization complete!');
    console.log('   Your database is now optimized for better performance.');
  } catch (error) {
    console.error('\n‚ùå Optimization failed:', error.message);
    process.exit(1);
  }
}

// Execute if run directly
if (require.main === module) {
  main().catch(console.error);
}

module.exports = { applyOptimizations, verifyOptimizations };
